## knn(k-NearestNeighbor, K近邻算法)

参考《机器学习实战》中的knn算法的实现， 计算输入数据和样本数据的欧几里得距离, 选取k个距离最短的样本, 然后选出k个样本中多数类作为输入数据的样本

#### 优点
> - 易于实现, 无需训练
> - 特别适合于多分类问题

#### 缺点
> - 当样本不平衡时会影响分类结果
> - 计算开销大, 因为需要计算输入数据和各个样本的距离, 造成时间和空间的开销很大, kd树是解决该问题的方法之一
